<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-EN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.0.2" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.0.2">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.0.2">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.0.2">


  <link rel="mask-icon" href="/images/logo.svg?v=6.0.2" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.0.2',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  
  <meta name="keywords" content="机器学习,集成学习,Boosting," />


<meta name="description" content="GBDT 1. 提升树 提升树是以分类树或回归树为基本分类器的提升方法。 1.1. 提升树模型 提升方法实际采用加法模型（即基函数的线性组合）与前向分步算法，以决策树为基函数的提升方法成为提升树（Boosting tree）。对分类问题决策树是二叉分类树，对回归问题决策树是二叉回归树。 提升树模型可以表示为决策树的加法模型： \[f_M(\pmb{x}) = \sum_{m=1}^M T(\pmb">
<meta name="keywords" content="机器学习,集成学习,Boosting">
<meta property="og:type" content="article">
<meta property="og:title" content="GBDT">
<meta property="og:url" content="http://yoursite.com/2018/03/10/机器学习/GBDT/index.html">
<meta property="og:site_name" content="silenove blogs">
<meta property="og:description" content="GBDT 1. 提升树 提升树是以分类树或回归树为基本分类器的提升方法。 1.1. 提升树模型 提升方法实际采用加法模型（即基函数的线性组合）与前向分步算法，以决策树为基函数的提升方法成为提升树（Boosting tree）。对分类问题决策树是二叉分类树，对回归问题决策树是二叉回归树。 提升树模型可以表示为决策树的加法模型： \[f_M(\pmb{x}) = \sum_{m=1}^M T(\pmb">
<meta property="og:locale" content="zh-EN">
<meta property="og:image" content="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-08%20下午5.05.48.png">
<meta property="og:image" content="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-10%20下午1.36.57.png">
<meta property="og:image" content="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-08%20下午7.48.46.png">
<meta property="og:image" content="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-10%20下午4.41.30.png">
<meta property="og:image" content="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-10%20下午7.18.02.png">
<meta property="og:image" content="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-10%20下午7.41.38.png">
<meta property="og:image" content="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-10%20下午7.42.06.png">
<meta property="og:image" content="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-10%20下午7.42.17.png">
<meta property="og:image" content="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-10%20下午7.42.27.png">
<meta property="og:updated_time" content="2018-03-10T12:01:40.374Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="GBDT">
<meta name="twitter:description" content="GBDT 1. 提升树 提升树是以分类树或回归树为基本分类器的提升方法。 1.1. 提升树模型 提升方法实际采用加法模型（即基函数的线性组合）与前向分步算法，以决策树为基函数的提升方法成为提升树（Boosting tree）。对分类问题决策树是二叉分类树，对回归问题决策树是二叉回归树。 提升树模型可以表示为决策树的加法模型： \[f_M(\pmb{x}) = \sum_{m=1}^M T(\pmb">
<meta name="twitter:image" content="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-08%20下午5.05.48.png">






  <link rel="canonical" href="http://yoursite.com/2018/03/10/机器学习/GBDT/"/>


  <title>GBDT | silenove blogs</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-EN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> <div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">silenove blogs</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">沿路旅程如歌褪变</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-home"></i> <br />Startseite</a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />Archiv</a>
        </li>
      

      
    </ul>
  

  
</nav>


  



 </div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/10/机器学习/GBDT/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="silen Zhou">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="silenove blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">GBDT</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-03-10T19:45:43+08:00">2018-03-10</time>
            

            
            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="gbdt">GBDT</h1>
<h2 id="提升树">1. 提升树</h2>
<p>提升树是以分类树或回归树为基本分类器的提升方法。</p>
<h3 id="提升树模型">1.1. 提升树模型</h3>
<p>提升方法实际采用加法模型（即基函数的线性组合）与前向分步算法，以决策树为基函数的提升方法成为提升树（Boosting tree）。对分类问题决策树是二叉分类树，对回归问题决策树是二叉回归树。<br>
提升树模型可以表示为决策树的加法模型： <span class="math display">\[f_M(\pmb{x}) = \sum_{m=1}^M T(\pmb{x};\Theta_m)\]</span> 其中，<span class="math inline">\(T(\pmb{x};\Theta_m)\)</span>表示决策树；<span class="math inline">\(\Theta_m\)</span>为决策树的参数，<span class="math inline">\(M\)</span>为树的个数。</p>
<h3 id="提升树算法">1.2. 提升树算法</h3>
<p>提升树算法采用前向分步算法。首先确定初始提升树<span class="math inline">\(f_0(\pmb{x}) = 0\)</span>，第<span class="math inline">\(m\)</span>步的模型是 <span class="math display">\[f_m(\pmb{x}) = f_{m-1}(\pmb{x}) + T(\pmb{x};\Theta_m)\]</span> 其中，<span class="math inline">\(f_{m-1}(\pmb{x})\)</span>为当前模型，通过经验风险最小化确定下一棵决策树的参数<span class="math inline">\(\Theta_m\)</span>： <span class="math display">\[\hat{\Theta}_m = \arg \min_{\Theta_m} \sum_{i=1}^N L(y_i,f_{m-1}(\pmb{x}_i)+T(\pmb{x}_i;\Theta_m))\]</span> 由于树的线性组合可以很好地拟合训练数据，即使数据中的输入与输出之间的关系很复杂也是如此，所以提升树是一个高功能的学习算法。<br>
针对不同问题的提升树学习算法，主要区别在于使用的损失函数不同：</p>
<ul>
<li>回归问题：平方误差损失函数；</li>
<li>分类问题：指数损失函数；</li>
<li>一般决策问题：一般损失函数。</li>
</ul>
<p>（1）<strong>二类分类问题</strong><br>
对于二类分类问题，提升树算法只需将AdaBoost算法中的基本分类器限制为二类分类树即可，可以说这时的提升树算法是AdaBoost算法的特殊情况。</p>
<p>（2）<strong>回归问题</strong><br>
已知一个训练数据集<span class="math display">\[T = \{(\pmb{x}_1,y_1),(\pmb{x}_2,y_2),\cdots,(\pmb{x}_N,y_N)\},\quad \pmb{x}_i \in \mathbf{R}^n, \quad y_i \in \mathbf{R}\]</span>。如果将输入空间划分为<span class="math inline">\(J\)</span>个互不相交的区域<span class="math inline">\(R_1,R_2,\cdots,R_J\)</span>，并且在每个区域上确定输出的常量<span class="math inline">\(c_j\)</span>，那么树可表示为 <span class="math display">\[T(\pmb{x};\Theta) = \sum_{j=1}^J c_j I(\pmb{x} \in R_j)\]</span> 其中，参数<span class="math inline">\(\Theta = \{(R_1,c_1),(R_2,c_2),\cdots,(R_J,c_J)\}\)</span>表示树的区域划分和各区域上的常数，<span class="math inline">\(J\)</span>是回归树的复杂度即叶节点个数。<br>
回归问题提升树使用以下前向分步算法：<br>
<span class="math display">\[\begin{align}
    f_0(\pmb{x}) &amp;= 0 \nonumber \\
    f_m(\pmb{x}) &amp;= f_{m-1}(\pmb{x}) + T(\pmb{x};\Theta_m), \quad m=1,2,\cdots,M \nonumber \\
    f_M(\pmb{x}) &amp;= \sum_{m=1}^M T(\pmb{x};\Theta_m) \nonumber 
\end{align}\]</span> 在前向分步算法的第<span class="math inline">\(m\)</span>步，给定当前模型<span class="math inline">\(f_{m-1}(\pmb{x})\)</span>，需求解 <span class="math display">\[\hat{\Theta}_m = \arg \min_{\Theta_m} \sum_{i=1}^N L(y_i,f_{m-1}(\pmb{x}_i)+T(\pmb{x}_i;\Theta_m))\]</span> 得到<span class="math inline">\(\hat{\Theta}_m\)</span>，即第<span class="math inline">\(m\)</span>棵树的参数。<br>
当采用平方误差损失函数时， <span class="math display">\[L(y,f(\pmb{x})) = (y-f(\pmb{x}))^2\]</span> 其损失变为 <span class="math display">\[\begin{align}
    L(y,f_{m-1}(\pmb{x}) + T(\pmb{x};\Theta_m)) &amp;= [y - f_{m-1}(\pmb{x}) - T(\pmb{x};\Theta_m)]^2 \nonumber \\
    &amp;= [r - T(\pmb{x};\Theta_m)]^2 \nonumber 
\end{align}\]</span> 这里 <span class="math display">\[r = y - f_{m-1}(\pmb{x})\]</span> <span class="math inline">\(r\)</span>是当前模型拟合数据的残差（residual）。所以，对于回归问题的提升树算法来说，只需要简单地拟合当前模型的残差。</p>
<div class="figure">
<img src="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-08%20下午5.05.48.png">

</div>
<h2 id="gbdt-1">2. GBDT</h2>
<p>GBDT是Boosting家族中另一个重要的算法梯度提升树（Gradient Boosting Decision Tree，GBDT），又叫MART（Multiple Additive Regression Tree, MART），是一种迭代的决策树算法。在传统的AdaBoost算法中，我们利用弱学习器的误差率来更新训练集的权重，这样一步步迭代下去。GBDT也是迭代，使用了前向分步算法，但是弱学习器限定了只能使用CART回归树模型，同时迭代思路和AdaBoost也有所不同。</p>
<h3 id="梯度提升">2.1. 梯度提升</h3>
<p>提升树利用加法模型与前向分步算法实现学习的优化过程，当损失函数是平方损失和指数损失函数时，每一步的优化是很简单的。但对一般损失函数而言，如绝对值和Huber损失函数，往往每一步的优化并不那么容易，针对这一问题，Freidman提出了梯度提升（gradient boosting）算法。这是利用最速下降法的近似方法，其关键是利用损失函数的负梯度在当前模型的值： <span class="math display">\[-[\frac{\partial L(y,f(\pmb{x}_i))}{\partial f(\pmb{x}_i)}]_{f(\pmb{x}) = f_{m-1}(\pmb{x})}\]</span> 用这个值作为回归问题提升树算法中的残差的近似值，拟合一个回归树。</p>
<div class="figure">
<img src="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-10%20下午1.36.57.png">

</div>
<h3 id="gbdt回归算法">2.2. GBDT回归算法</h3>
<div class="figure">
<img src="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-08%20下午7.48.46.png">

</div>
<p>算法第一步初始化，估计使损失函数极小化的常数值，它是只有一个根节点的树。第2（a）步计算损失函数的负梯度在当前模型的值，将它作为残差的估计。对于平方损失函数，它就是通常所说的残差；对于一般损失函数，它就是残差的近似值。第2（b）步估计回归树叶节点区域，以拟合残差的近似值。第2（c）步利用线性搜索估计叶节点区域的值，使损失函数极小化。第2（d）步更新回归树。第3步得到输出的最终模型<span class="math inline">\(\hat{f}(\pmb{x})\)</span>。</p>
<h3 id="gbdt分类算法">2.3. GBDT分类算法</h3>
<p>GBDT的分类算法从思想上和GBDT的回归算法没有区别，但是由于样本输出不是连续值，而是离散的类别，导致无法直接从输出类别去拟合类别输出的误差。<br>
为了解决这个问题，主要有两种方法：</p>
<ol style="list-style-type: decimal">
<li>用指数损失函数，此时GBDT退化为AdaBoost算法；</li>
<li>用类似于逻辑回归的对数似然损失函数的方法，用类别的预测概率值和真实概率值的差来拟合损失。</li>
</ol>
<p>下面主要讨论用对数似然损失函数的GBDT分类，而对于对数似然损失函数，又有二元分类和多元分类的区别。</p>
<h4 id="二元gbdt分类算法">2.3.1. 二元GBDT分类算法</h4>
<p>对于二元GBDT，如果用二元Logistic回归损失函数，则损失函数为 <span class="math display">\[L(y,F) = \log (1 + \exp(-2 y F))\]</span> 其中<span class="math inline">\(y \in \{-1,+1\}\)</span>，并且 <span class="math display">\[F(\pmb{x}) = \frac{1}{2} \log [\frac{P(y=1|\pmb{x})}{P(y=-1|\pmb{x})}]\]</span> 此时的负梯度误差为 <span class="math display">\[\tilde{y}_i = -[\frac{\partial L(y_i,F(\pmb{x}_i))}{\partial F(\pmb{x}_i)}]_{F(\pmb{x}) = F_{m-1}(\pmb{x})} = \frac{2y_i}{1+\exp(2 y_i F_{m-1}(\pmb{x}_i))}\]</span> 对于生成的决策树，各个子节点的最佳残差拟合值为 <span class="math display">\[\gamma_{lm} = \arg \min_{\gamma} \sum_{\pmb{x}_i \in R_{lm}} \log(1+\exp(-2y_i (F_{m-1}(\pmb{x})+\gamma)))\]</span> 由于上式无法求得闭式解，所以根据Newton-Raphson方法求其近似解，得到 <span class="math display">\[\gamma_{lm} = \frac{\sum_{\pmb{x}_i \in R_{lm}} \tilde{y}_i}{\sum_{\pmb{x}_i \in R_{lm}} |\tilde{y}_i| (2 - |\tilde{y}_i|)}\]</span> 更新公式为 <span class="math display">\[F_m(\pmb{x}) = F_{m-1}(\pmb{x}) + \gamma_{lm} 1(\pmb{x} \in R_{lm})\]</span></p>
<p>算法如下：</p>
<div class="figure">
<img src="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-10%20下午4.41.30.png">

</div>
<p>得到最终的强学习器<span class="math inline">\(F_M(\pmb{x})\)</span>的预测值与对数几率相关，可转化为概率预测值： <span class="math display">\[\begin{align}
    p_+(\pmb{x}) &amp;= \hat{P}(y=1|\pmb{x}) = \frac{1}{1+\exp(-2 F_M(\pmb{x}))} \nonumber \\
     p_-(\pmb{x}) &amp;= \hat{P}(y=-1|\pmb{x}) = \frac{1}{1+\exp(2 F_M(\pmb{x}))} \nonumber
\end{align}\]</span></p>
<p>可用如下公式进行分类： <span class="math display">\[\hat{y}(\pmb{x}) = 2· 1[c(-1,1)p_+(\pmb{x}) &gt; c(1,-1)p_-(\pmb{x})] - 1\]</span> 其中<span class="math inline">\(c(\hat{y},y)\)</span>是将真实标记<span class="math inline">\(y\)</span>预测为<span class="math inline">\(\hat{y}\)</span>的损失代价。</p>
<h4 id="多元gbdt分类算法">2.3.2. 多元GBDT分类算法</h4>
<p>假设类别数为<span class="math inline">\(K\)</span>，对应的损失函数为 <span class="math display">\[L(\{y_k, F_k(\pmb{x})\}_1^K) = - \sum_{k=1}^K y_k \log p_k(\pmb{x})\]</span> 其中，当类别为<span class="math inline">\(k\)</span>时，<span class="math inline">\(y_k = 1 \in \{0,1\}\)</span>，<span class="math inline">\(p_k(\pmb{x}) = P(y_k=1|\pmb{x})\)</span>。<br>
使用对称多元logistic转换，即 <span class="math display">\[F_k(\pmb{x}) = \log p_k(\pmb{x}) - \frac{1}{K} \sum_{l=1}^K \log p_l (\pmb{x})\]</span> 或者，等价于 <span class="math display">\[p_k(\pmb{x}) = \frac{\exp(F_k(\pmb{x}))}{\sum_{l=1}^K \exp(F_l(\pmb{x}))}\]</span> 此时负梯度误差为 <span class="math display">\[\tilde{y}_{ik} = - [\frac{\partial L(\{y_{ij}, F_{ij}(\pmb{x}_i)\}_{j=1}^K)}{\partial F_k(\pmb{x}_i)}]_{\{F_j(\pmb{x}) = F_{j,m-1}(\pmb{x})\}_1^K} = y_{ik} - p_k(\pmb{x}_i)\]</span> 根据对应的残差生成<span class="math inline">\(K\)</span>棵决策树，每一棵决策树都是为了拟合对应的残差<span class="math inline">\(\{y_{ik} - p_k(\pmb{x}_i)\}_{i=1}^N\)</span>。其中第<span class="math inline">\(k\)</span>棵树的第<span class="math inline">\(l\)</span>个子节点在第<span class="math inline">\(m\)</span>轮对应划分的训练集区域为<span class="math inline">\(R_{klm}\)</span>，最佳残差拟合值为 <span class="math display">\[\gamma_{klm} = \arg \min_{\gamma} \sum_{\pmb{x}_i \in R_{klm}} \phi_k (y_{ik}, F_{k,m-1}(\pmb{x}_i)+ \gamma)\]</span> 其中<span class="math inline">\(\phi_k = - y_k \log p_k(\pmb{x})\)</span>，式中<span class="math inline">\(p_k(\pmb{x}) = \frac{\exp(F_k(\pmb{x}))}{\sum_{l=1}^K \exp(F_l(\pmb{x}))}\)</span>。<br>
由于上式无法求得闭式解，所以根据Newton-Raphson方法求其近似解，得到 <span class="math display">\[\gamma_{klm} = \frac{K-1}{K} \frac{\sum_{\pmb{x}_i \in R_{klm}}\tilde{y}_{ik}}{\sum_{\pmb{x}_i \in R_{klm}} |\tilde{y}_{ik}|(1- |\tilde{y}_{ik}|)}\]</span> 更新公式为 <span class="math display">\[F_{km}(\pmb{x}) = F_{k,m-1}(\pmb{x}) + \gamma_{klm} 1(\pmb{x} \in R_{klm})\]</span></p>
<p>算法如下：</p>
<div class="figure">
<img src="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-10%20下午7.18.02.png">

</div>
<p>最终得到的强分类器<span class="math inline">\(\{F_{kM}(\pmb{x})\}_1^K\)</span>可以通过公式<span class="math inline">\(p_k(\pmb{x}) = \frac{\exp(F_k(\pmb{x}))}{\sum_{l=1}^K \exp(F_l(\pmb{x}))}\)</span>计算对应的概率<span class="math inline">\(\{p_{kM}(\pmb{x})\}_1^K\)</span>，并可以用来进行分类 <span class="math display">\[\hat{k}(\pmb{x}) = \arg \min_{1 \leq k \leq K} \sum_{k&#39;=1}^K c(k,k&#39;)p_{k&#39;M}(\pmb{x})\]</span> 其中<span class="math inline">\(c(k,k&#39;)\)</span>是将真实标记<span class="math inline">\(k&#39;\)</span>预测为<span class="math inline">\(k\)</span>的损失代价，当<span class="math inline">\(K=2\)</span>时，多元GBDT分类算法与二类GBDT分类算法相同。</p>
<h2 id="sklearn使用">3. sklearn使用</h2>
<p>在sklearn中，有GradientBoostingClassifier和GradientBoostingRegressor分别用来分类和回归。</p>
<p>GradientBoostingClassifier：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">sklearn</span>.<span class="title">ensemble</span>.<span class="title">GradientBoostingClassifier</span><span class="params">(loss=’deviance’, learning_rate=<span class="number">0.1</span>, n_estimators=<span class="number">100</span>, subsample=<span class="number">1.0</span>, criterion=’friedman_mse’, min_samples_split=<span class="number">2</span>, min_samples_leaf=<span class="number">1</span>, min_weight_fraction_leaf=<span class="number">0.0</span>, max_depth=<span class="number">3</span>, min_impurity_decrease=<span class="number">0.0</span>, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=<span class="number">0</span>, max_leaf_nodes=None, warm_start=False, presort=’auto’)</span></span></span><br></pre></td></tr></table></figure>
<p>GradientBoostingRegressor：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">sklearn</span>.<span class="title">ensemble</span>.<span class="title">GradientBoostingRegressor</span><span class="params">(loss=’ls’, learning_rate=<span class="number">0.1</span>, n_estimators=<span class="number">100</span>, subsample=<span class="number">1.0</span>, criterion=’friedman_mse’, min_samples_split=<span class="number">2</span>, min_samples_leaf=<span class="number">1</span>, min_weight_fraction_leaf=<span class="number">0.0</span>, max_depth=<span class="number">3</span>, min_impurity_decrease=<span class="number">0.0</span>, min_impurity_split=None, init=None, random_state=None, max_features=None, alpha=<span class="number">0.9</span>, verbose=<span class="number">0</span>, max_leaf_nodes=None, warm_start=False, presort=’auto’)</span>[<span class="title">source</span>]</span></span><br></pre></td></tr></table></figure>
<p><strong>框架参数</strong></p>
<div class="figure">
<img src="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-10%20下午7.41.38.png">

</div>
<p><strong>弱分类器参数</strong>：即决策树参数</p>
<div class="figure">
<img src="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-10%20下午7.42.06.png">

</div>
<p><strong>函数</strong> <img src="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-10%20下午7.42.17.png"></p>
<p><strong>属性</strong> <img src="http://p35icynkw.bkt.clouddn.com/屏幕快照%202018-03-10%20下午7.42.27.png"></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/集成学习/" rel="tag"># 集成学习</a>
          
            <a href="/tags/Boosting/" rel="tag"># Boosting</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/03/08/机器学习/AdaBoost/" rel="next" title="AdaBoost">
                <i class="fa fa-chevron-left"></i> AdaBoost
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/03/11/碎碎/泰勒公式/" rel="prev" title="泰勒公式">
                泰勒公式 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Übersicht
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">silen Zhou</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">27</span>
                    <span class="site-state-item-name">Artikel</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    <span class="site-state-item-count">18</span>
                    <span class="site-state-item-name">Tags</span>
                  
                </div>
              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#gbdt"><span class="nav-number">1.</span> <span class="nav-text">GBDT</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#提升树"><span class="nav-number">1.1.</span> <span class="nav-text">1. 提升树</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#提升树模型"><span class="nav-number">1.1.1.</span> <span class="nav-text">1.1. 提升树模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#提升树算法"><span class="nav-number">1.1.2.</span> <span class="nav-text">1.2. 提升树算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#gbdt-1"><span class="nav-number">1.2.</span> <span class="nav-text">2. GBDT</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度提升"><span class="nav-number">1.2.1.</span> <span class="nav-text">2.1. 梯度提升</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gbdt回归算法"><span class="nav-number">1.2.2.</span> <span class="nav-text">2.2. GBDT回归算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gbdt分类算法"><span class="nav-number">1.2.3.</span> <span class="nav-text">2.3. GBDT分类算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#二元gbdt分类算法"><span class="nav-number">1.2.3.1.</span> <span class="nav-text">2.3.1. 二元GBDT分类算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#多元gbdt分类算法"><span class="nav-number">1.2.3.2.</span> <span class="nav-text">2.3.2. 多元GBDT分类算法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sklearn使用"><span class="nav-number">1.3.</span> <span class="nav-text">3. sklearn使用</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">silen Zhou</span>

  

  
</div>




  <div class="powered-by">Erstellt mit  <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Muse</a> v6.0.2</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.0.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.0.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.0.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.0.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.0.2"></script>



  



	





  





  










  





  

  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
  


  
  

  

  

  

  

</body>
</html>
